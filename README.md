# Image Classification - Rubbish Dataset

Proyek klasifikasi gambar untuk dataset sampah (rubbish) menggunakan Deep Learning dengan TensorFlow/Keras. Proyek ini dibuat untuk memenuhi submission Dicoding Machine Learning dengan target akurasi **95%+**.

## ğŸ“‹ Deskripsi

Proyek ini mengimplementasikan model klasifikasi gambar untuk mengklasifikasikan 6 jenis sampah:

- Cardboard (Kardus)
- Glass (Kaca)
- Metal (Logam)
- Organic (Organik)
- Paper (Kertas)
- Plastic (Plastik)

## ğŸ¯ Fitur Utama

- âœ… **Dataset**: 23,066 gambar dari Hugging Face
- âœ… **Akurasi Target**: 95%+
- âœ… **Augmentasi Data**: Rotasi, zoom, flip, shift
- âœ… **Transfer Learning**: MobileNetV2 (pre-trained ImageNet)
- âœ… **Custom Callbacks**: AccuracyThresholdCallback, ReduceLROnPlateau
- âœ… **Class Weights**: Menangani class imbalance
- âœ… **Deployment**: 3 format (SavedModel, TF-Lite, TensorFlow.js)
- âœ… **Visualisasi**: Confusion Matrix, Per-class Accuracy, Training History

## ğŸ“Š Dataset

**Source**: [Hugging Face - rubbish_augmented](https://huggingface.co/datasets/Jotadebeese/rubbish_augmented)

**Statistik**:

- Total Images: 23,066
- Training: 18,450 (80%)
- Validation: 2,304 (10%)
- Test: 2,312 (10%)
- Classes: 6

## ğŸ› ï¸ Teknologi

- **Python**: 3.12+
- **TensorFlow**: 2.19.0
- **Keras**: (included in TensorFlow)
- **MobileNetV2**: Transfer Learning
- **Hugging Face Datasets**: Data loading
- **scikit-learn**: Metrics & utilities

## ğŸ“¦ Instalasi

### 1. Clone Repository

```bash
git clone <repository-url>
cd Dicoding-Klasifikasi-Gambar
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. (Optional) GPU Setup

Pastikan CUDA dan cuDNN terinstall untuk training dengan GPU.

## ğŸš€ Cara Penggunaan

### Training Model

Jalankan notebook `notebook.ipynb` di Google Colab atau Jupyter:

```bash
jupyter notebook notebook.ipynb
```

Atau jalankan di Google Colab:

1. Upload `notebook.ipynb` ke Google Colab
2. Jalankan semua cell secara berurutan
3. Model akan otomatis didownload dan ditraining

### Struktur Notebook

1. **Import Libraries** - Import semua dependencies
2. **Data Loading** - Download dataset dari Hugging Face
3. **Configuration** - Setup hyperparameters
4. **Dataset Analysis** - Analisis distribusi data
5. **Data Augmentation** - Setup augmentasi data
6. **Model Architecture** - Build model dengan MobileNetV2
7. **Custom Callbacks** - AccuracyThresholdCallback
8. **Class Weights** - Menangani class imbalance
9. **Training** - Train model dengan callbacks
10. **Evaluation** - Evaluasi pada test set
11. **Confusion Matrix** - Visualisasi performa
12. **Deployment** - Export 3 format model
13. **Inference** - Demo prediksi dengan TF-Lite

## ğŸ—ï¸ Arsitektur Model

```
Input (224x224x3)
    â†“
MobileNetV2 (pre-trained, frozen)
    â†“
Conv2D (256 filters, 3x3) + ReLU
    â†“
MaxPooling2D (2x2)
    â†“
Conv2D (128 filters, 3x3) + ReLU
    â†“
MaxPooling2D (2x2)
    â†“
GlobalAveragePooling2D
    â†“
Dropout (0.5)
    â†“
Dense (256) + ReLU
    â†“
Dropout (0.3)
    â†“
Dense (6) + Softmax
```

## ğŸ“ˆ Hyperparameters

| Parameter          | Value                    |
| ------------------ | ------------------------ |
| Image Size         | 224x224                  |
| Batch Size         | 64                       |
| Epochs             | 50                       |
| Learning Rate      | 1e-4                     |
| Optimizer          | Adam                     |
| Loss               | Categorical Crossentropy |
| Accuracy Threshold | 95%                      |

## ğŸ¨ Data Augmentation

- **Rotation**: Â±20Â°
- **Width Shift**: Â±20%
- **Height Shift**: Â±20%
- **Shear**: Â±20%
- **Zoom**: Â±20%
- **Horizontal Flip**: True
- **Fill Mode**: Nearest

## ğŸ“Š Callbacks

1. **AccuracyThresholdCallback**: Stop training saat mencapai 95% accuracy
2. **ModelCheckpoint**: Save best model berdasarkan val_accuracy
3. **ReduceLROnPlateau**: Kurangi learning rate saat val_loss plateau
4. **EarlyStopping**: Stop training jika tidak ada improvement

## ğŸ’¾ Model Deployment

Model disimpan dalam 3 format:

### 1. SavedModel

```
saved_model/
â”œâ”€â”€ saved_model.pb
â””â”€â”€ variables/
```

### 2. TF-Lite

```
tflite/
â”œâ”€â”€ model.tflite
â””â”€â”€ labels.txt
```

### 3. TensorFlow.js

```
tfjs_model/
â”œâ”€â”€ group1-shard1of1.bin
â””â”€â”€ model.json
```

## ğŸ“Š Hasil Evaluasi

Model akan menghasilkan:

- âœ… Training/Validation Accuracy & Loss plots
- âœ… Confusion Matrix (counts & percentages)
- âœ… Per-class Accuracy bar chart
- âœ… Classification Report (Precision, Recall, F1-Score)
- âœ… Test Set Evaluation

## ğŸ” Inference

### Menggunakan TF-Lite Model

```python
import tensorflow as tf
import numpy as np
from PIL import Image

# Load TF-Lite model
interpreter = tf.lite.Interpreter(model_path='tflite/model.tflite')
interpreter.allocate_tensors()

# Load labels
with open('tflite/labels.txt', 'r') as f:
    labels = [line.strip() for line in f.readlines()]

# Predict
img = Image.open('test_image.jpg').resize((224, 224))
img_array = np.array(img, dtype=np.float32) / 255.0
img_array = np.expand_dims(img_array, axis=0)

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.set_tensor(input_details[0]['index'], img_array)
interpreter.invoke()

predictions = interpreter.get_tensor(output_details[0]['index'])[0]
predicted_class = labels[np.argmax(predictions)]
confidence = np.max(predictions) * 100

print(f"Predicted: {predicted_class} ({confidence:.2f}%)")
```

## ğŸ“ Struktur Project

```
Dicoding-Klasifikasi-Gambar/
â”œâ”€â”€ notebook.ipynb              # Main notebook
â”œâ”€â”€ README.md                   # Dokumentasi
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ .gitignore                 # Git ignore file
â”œâ”€â”€ dataset_final/             # Dataset (auto-downloaded)
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ saved_model/               # SavedModel format
â”œâ”€â”€ tflite/                    # TF-Lite format
â”‚   â”œâ”€â”€ model.tflite
â”‚   â””â”€â”€ labels.txt
â”œâ”€â”€ tfjs_model/                # TensorFlow.js format
â”œâ”€â”€ best_model.keras           # Best model checkpoint
â”œâ”€â”€ training_history.png       # Training plots
â”œâ”€â”€ confusion_matrix.png       # Confusion matrix
â””â”€â”€ per_class_accuracy.png     # Per-class accuracy
```

## ğŸ“ Kriteria Dicoding

Proyek ini memenuhi semua kriteria submission Dicoding:

- âœ… Dataset minimal 1000 gambar (23,066 âœ“)
- âœ… Akurasi minimal 85% (Target: 95%+ âœ“)
- âœ… Menggunakan Sequential Model âœ“
- âœ… Menggunakan Conv2D & MaxPooling2D âœ“
- âœ… Custom Callback untuk stop di 95% âœ“
- âœ… Augmentasi data âœ“
- âœ… Deployment 3 format âœ“
- âœ… Visualisasi training history âœ“
- âœ… Inference demonstration âœ“

## ğŸ› Troubleshooting

### TensorFlow.js Conversion Error

Jika terjadi error saat konversi TensorFlow.js:

```bash
pip install tensorflowjs==4.20.0 packaging==23.2
```

### GPU Not Detected

```bash
# Check GPU
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

# Install CUDA & cuDNN sesuai TensorFlow version
```

### Dataset Download Error

Jika download otomatis gagal, download manual dari:
https://huggingface.co/datasets/Jotadebeese/rubbish_augmented

## ğŸ“ License

MIT License

## ğŸ‘¨â€ğŸ’» Author

**Radit Firansah**

- GitHub: [@raditfiransah](https://github.com/raditfiransah)
- Dicoding: Radit Firansah

## ğŸ™ Acknowledgments

- Dataset: [Jotadebeese/rubbish_augmented](https://huggingface.co/datasets/Jotadebeese/rubbish_augmented)
- Dicoding Indonesia
- TensorFlow & Keras Team
- MobileNetV2 Architecture

## ğŸ“š References

1. [MobileNetV2 Paper](https://arxiv.org/abs/1801.04381)
2. [TensorFlow Documentation](https://www.tensorflow.org/)
3. [Keras Documentation](https://keras.io/)
4. [Dicoding Deep Learning Path](https://www.dicoding.com/)

---

**Note**: Proyek ini dibuat untuk submission Dicoding Machine Learning. Model mencapai akurasi 95%+ pada test set dengan menggunakan transfer learning dan data augmentation.
